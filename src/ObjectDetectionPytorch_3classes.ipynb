{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "BMmgkneXpFlM",
    "outputId": "9ffa98e8-2651-47d4-bb7f-e16c718d153a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finnes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pycocotools\n",
    "os.getcwd()\n",
    "if os.path.isdir('pytorchObjectDetection'):\n",
    "    print(\"finnes\")\n",
    "    os.chdir('pytorchObjectDetection')\n",
    "else:\n",
    "    os.chdir('pytorchObjectDetection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hOiAek98pcnN",
    "outputId": "0c0ccee7-dd9b-40d2-94be-4e877d81ffc2"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "git clone https://github.com/pytorch/vision.git\n",
    "cd vision\n",
    "git checkout v0.3.0\n",
    "cp references/detection/utils.py ../\n",
    "cp references/detection/transforms.py ../\n",
    "cp references/detection/coco_eval.py ../\n",
    "cp references/detection/engine.py ../\n",
    "cp references/detection/coco_utils.py ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vLYciXRvppYM"
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import pandas as pd\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "import transforms as T\n",
    "import torchvision\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "akEhpNBwpFlN"
   },
   "outputs": [],
   "source": [
    "def extract_BBoxes(filename):\n",
    "   \n",
    "    root = ET.parse(filename).getroot()\n",
    "    \n",
    "    boxes = list()\n",
    "    names = list()\n",
    "    for objct in root.findall(\".//object\"):\n",
    "        name = objct.find('name').text\n",
    "        xmin = int(objct.find('bndbox/xmin').text)\n",
    "        ymin = int(objct.find('bndbox/ymin').text)\n",
    "        xmax = int(objct.find('bndbox/xmax').text)\n",
    "        ymax = int(objct.find('bndbox/ymax').text)\n",
    "        names.append(name)\n",
    "        boxes.append([xmin,ymin,xmax,ymax])\n",
    "\n",
    "    return [boxes,names]\n",
    "    \n",
    "def load_dataset(path, deleteFiles = False):\n",
    "    files_xml = [f for f in glob.glob(path + \"/*.xml\")] # comes in random order\n",
    "\n",
    "    \n",
    "    imgbbox = dict()\n",
    "    print(len(files_xml))\n",
    "    for file in files_xml:  \n",
    "        \n",
    "        imgFilePath = file[:-3] + \"jpg\"\n",
    "        if os.path.exists(imgFilePath):  \n",
    "            lbl_bbox = extract_BBoxes(file)  # Gets the bbox information\n",
    "            \n",
    "            #print(lbl_bbox[0])\n",
    "            \n",
    "            imgbbox.update({imgFilePath.replace(path+\"/\",''): lbl_bbox})\n",
    "            \n",
    "        elif deleteFiles:\n",
    "            print(\"Found xml with no jpg\")\n",
    "            print(\"Deleting xml file: %s\" %file)\n",
    "            os.remove(file)\n",
    "            print(\"Deleted\")\n",
    "\n",
    "    return imgbbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13. FasterRCNN.html              \u001b[1m\u001b[36mProject2\u001b[m\u001b[m\n",
      "B0010_0006.png                   README.md\n",
      "Baggage.ipynb                    gun.jpg\n",
      "\u001b[1m\u001b[36mBaggages\u001b[m\u001b[m                         movie.gif\n",
      "\u001b[1m\u001b[36mBaggages 2\u001b[m\u001b[m                       \u001b[1m\u001b[36mpytorchObjectDetection\u001b[m\u001b[m\n",
      "Baggages_data.zip                setup.ipynb\n",
      "\u001b[1m\u001b[36mBoundingBox-master\u001b[m\u001b[m               \u001b[1m\u001b[36msrc\u001b[m\u001b[m\n",
      "ObjectDetectionPytorch.ipynb     \u001b[1m\u001b[36mtemp\u001b[m\u001b[m\n",
      "ObjectDetectionPytorchXRAY.ipynb \u001b[1m\u001b[36mtrainedModels\u001b[m\u001b[m\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iVlv1ihLqzr8",
    "outputId": "bc7ad9d8-7223-4ca0-8951-09924818ba7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[[6, 41, 121, 383], [128, 30, 221, 390], [219, 38, 320, 412]],\n",
       " ['rifle', 'rifle', 'rifle']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')\n",
    "#pathDataset = 'drive/MyDrive/Project2'\n",
    "pathDataset = './Project2'\n",
    "imgbbox = load_dataset(pathDataset, deleteFiles=False)\n",
    "imgbbox['2 (202).jpg']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZad7ZIgrhLN"
   },
   "source": [
    "Obtaining the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5t_Hw-HvrzM6"
   },
   "source": [
    "Class containing all data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BDaSI_dsrki-"
   },
   "outputs": [],
   "source": [
    "class GunDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, dicPics, categories, path, transforms=None): \n",
    "        self.path = path\n",
    "        self.dicPics = dicPics\n",
    "        self.transforms = transforms\n",
    "        self.categories = categories\n",
    "        self.imgs = [o for o in dicPics]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        print(\"path = \", )\n",
    "        print(self.path +\"/\"+ self.imgs[idx])\n",
    "        img = Image.open(self.path +\"/\"+ self.imgs[idx]).convert(\"RGB\")        \n",
    "        box_list = self.dicPics[self.imgs[idx]][0]\n",
    "        \n",
    "        boxes = torch.as_tensor(box_list, dtype=torch.float32)\n",
    "        num_objs = len(box_list)\n",
    "        labels_list =  self.dicPics[self.imgs[idx]][1]\n",
    "\n",
    "        # there is only one class\n",
    "        #labels = torch.ones((num_objs,), dtype=torch.int64) \n",
    "\n",
    "        # multible classes\n",
    "        labels = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        for i in range(num_objs):\n",
    "            labels[i] = self.categories[labels_list[i]]\n",
    "        #print(labels)\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:,0])\n",
    "\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "        \n",
    "        return img, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4f50oQXtcpr"
   },
   "source": [
    "Checks if the class is correct and returns the expected values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9EyrKUsKsFlU",
    "outputId": "c4d45ea7-d89b-40ce-96ba-2cc409c451a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path = \n",
      "./Project2/1 (198).jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<PIL.Image.Image image mode=RGB size=320x450 at 0x7F8EECEF4630>,\n",
       " {'boxes': tensor([[118., 116., 186., 177.]]),\n",
       "  'labels': tensor([1]),\n",
       "  'image_id': tensor([10]),\n",
       "  'area': tensor([4148.]),\n",
       "  'iscrowd': tensor([0])})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = {'handgun': 1,'rifle': 2}\n",
    "dataset = GunDataset(dicPics = imgbbox,categories = cat, path = pathDataset, transforms = None) #, categories = cat\n",
    "dataset.__getitem__(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "id": "OiKnyvGO0h3I",
    "outputId": "69c375c4-6ee0-4569-c830-ea65d2699402"
   },
   "outputs": [],
   "source": [
    "image = Image.open(pathDataset + '/1 (107).jpg')\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vByvVLARtk8q"
   },
   "source": [
    "Downloads and configures the model for our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BdcuDZgAsM4R"
   },
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "  # load an object detection model pre-trained on COCO\n",
    "  model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "  # get the number of input features for the classifier\n",
    "  in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "  # replace the pre-trained head with a new on\n",
    "  model.roi_heads.box_predictor = FastRCNNPredictor(in_features,num_classes)\n",
    "   \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tWKIW6W8t33m"
   },
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "   # converts the image, a PIL image, into a PyTorch Tensor\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "      # during training, randomly flip the training images\n",
    "      # and ground-truth for data augmentation\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51-JXik-uAlG",
    "outputId": "789d86fe-aa21-4c67-cb59-063fa975472d"
   },
   "outputs": [],
   "source": [
    "# use our dataset and defined transformations\n",
    "dataset = GunDataset(dicPics=imgbbox, categories = cat, path = pathDataset, transforms = get_transform(train=True))      # Training\n",
    "dataset_test = GunDataset(dicPics = imgbbox, categories = cat, path = pathDataset, transforms = get_transform(train=False)) # Testing\n",
    "\n",
    "# split the dataset in train and test set\n",
    "torch.manual_seed(1)\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:-40])  \n",
    "#dataset = torch.utils.data.Subset(dataset, indices[:100])  # testing\n",
    "\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-40:])\n",
    "#dataset_test = torch.utils.data.Subset(dataset_test, indices[-30:])\n",
    "\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "              dataset, batch_size=2, shuffle=True, num_workers=4,\n",
    "              collate_fn=utils.collate_fn)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "         dataset_test, batch_size=1, shuffle=False, num_workers=4,\n",
    "         collate_fn=utils.collate_fn)\n",
    "\n",
    "print(\"We have: {} examples, {} are training and {} testing\".format(len(indices), len(dataset), len(dataset_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CD6I0fXyuilM",
    "outputId": "630d7288-087d-4121-8b48-281d9a816038"
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 83,
     "referenced_widgets": [
      "d79960d69fc54f07aeabc2718f6f9b94",
      "3f785a7cf78f4e328124fdb191ed5b72",
      "296c1962e21f4f4081672e6bb3054067",
      "ab035faa95b24017baad2705bceb8cf5",
      "f923e0f54ee0426184cbe11c9cd06882",
      "fa6b424815754a029660856b6fac6814",
      "9146bcaa47354f1ca72cb71a145b73c9",
      "41a7da1582974468b550dae41b1cbcee"
     ]
    },
    "id": "qgjqrxZeu3gH",
    "outputId": "afe185e3-31d8-4003-ab3a-7755d0bbfe94"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# our dataset has two classes only - gun and not gun\n",
    "num_classes = 3\n",
    "# get the model using our helper function\n",
    "model = get_model(num_classes)\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# and a learning rate scheduler which decreases the learning rate by # 10x every 3 epochs\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0b-LLxtupFlP"
   },
   "source": [
    "## TRAIN NEW MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fNA-M_2bwNiW",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "9ec5525c-987c-4141-c59c-0fb8f8741e77"
   },
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 8\n",
    "for epoch in range(num_epochs):\n",
    "   # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "# update the learning rate\n",
    "\n",
    "    lr_scheduler.step()\n",
    "   # evaluate on the test dataset\n",
    "   # evaluate(model, data_loader_test, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pc01-dAC3lgJ",
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    " # Saves model to folder trainedModels\n",
    "    \n",
    "path_trnd_model = \"drive/MyDrive/trainedModels\"\n",
    "if os.path.isdir(path_trnd_model) is False:\n",
    "    os.mkdir(path_trnd_model)\n",
    "\n",
    "state = {'epoch': num_epochs +1, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict() }\n",
    "torch.save(state, path_trnd_model+\"/model_3Classes_10epochs\")\n",
    "\n",
    "#torch.save(model.state_dict(), )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ax6rbjcpFlP"
   },
   "source": [
    "## TRAIN OLD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6swBoWihpFlP"
   },
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer=None, filename=None):\n",
    "    # Note: Input model & optimizer should be pre-defined.  This routine only updates their states.\n",
    "    start_epoch = 0\n",
    "    if os.path.isfile(filename):\n",
    "        print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "        checkpoint = torch.load(filename)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        if optimizer is not None:\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(filename, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(filename))\n",
    "\n",
    "    return model, optimizer, start_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tJmsgJ52pFlP",
    "outputId": "475fa1c6-f8d0-4197-b7a4-f2ad2c4c94af"
   },
   "outputs": [],
   "source": [
    "model, optimizer, start_epoch = load_checkpoint(get_model(num_classes = 3), optimizer, filename=path_trnd_model+\"/model_3Classes_20epochs\")\n",
    "model = model.to(device)\n",
    "\n",
    "# individually transfer the optimizer parts...\n",
    "for state in optimizer.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F2euKDbwpFlP",
    "jupyter": {
     "source_hidden": true
    },
    "outputId": "fd6b50c7-4832-42a1-f259-ded169f0318b"
   },
   "outputs": [],
   "source": [
    "# let's train it for 0 epochs\n",
    "num_epochs = 12\n",
    "for epoch in range(num_epochs):\n",
    "   # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "# update the learning rate\n",
    "\n",
    "    lr_scheduler.step()\n",
    "   # evaluate on the test dataset\n",
    "   # evaluate(model, data_loader_test, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mglK4EjwpFlP"
   },
   "outputs": [],
   "source": [
    "state = {'epoch': num_epochs +1, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict() }\n",
    "torch.save(state, path_trnd_model+\"/model_3Classes_20epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjmH7dJmpFlP"
   },
   "source": [
    "# PREDICT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DC_akS85pFlP",
    "outputId": "d28d3deb-60d7-4473-ce8f-5fb574af6c5e"
   },
   "outputs": [],
   "source": [
    "# To load trained model\n",
    "#path_trnd_model = \"drive/MyDrive/trainedModels\"\n",
    "print(os.getcwd())\n",
    "path_trnd_model = \"../trainedModels\"\n",
    "\n",
    "# To load trained model\n",
    "loaded_model = get_model(num_classes = 3)\n",
    "loaded_model.load_state_dict(torch.load(path_trnd_model+\"/model_3Classes_20epochs_finished\", map_location=torch.device(\"cpu\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "rlaPAHag34ee",
    "outputId": "f633157b-d228-48c7-b7ec-8d856b115dd3"
   },
   "outputs": [],
   "source": [
    "idx = 1\n",
    "\n",
    "img, _ = dataset_test[idx]\n",
    "label_boxes = np.array(dataset_test[idx][1][\"boxes\"])\n",
    "\n",
    "#put the model in evaluation mode\n",
    "loaded_model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = loaded_model([img])\n",
    "\n",
    "image = Image.fromarray(img.mul(255).permute(1, 2,0).byte().numpy())\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "cat_rev = {cat[o]: o for o in cat}\n",
    "# draw groundtruth\n",
    "for elem in range(len(label_boxes)):\n",
    "    draw.rectangle([(label_boxes[elem][0], label_boxes[elem][1]),\n",
    "    (label_boxes[elem][2], label_boxes[elem][3])], \n",
    "    outline =\"green\", width =3)\n",
    "\n",
    "for element in range(len(prediction[0][\"boxes\"])):\n",
    "\n",
    "    boxes = prediction[0][\"boxes\"][element].cpu().numpy()\n",
    "    score = np.round(prediction[0][\"scores\"][element].cpu().numpy(),\n",
    "                    decimals= 4)\n",
    "    if score > 0.7:\n",
    "        draw.rectangle([(boxes[0], boxes[1]), (boxes[2], boxes[3])], outline =\"red\", width =3)\n",
    "        draw.text((boxes[0], boxes[1]), text = str(score)+ \" \" + cat_rev[np.int(prediction[0][\"labels\"][element])] , fill=\"#000\")\n",
    "display(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_loader(image_path, imgname):\n",
    "    imgtextbbox = {imgname: [[[0,0,0,0]],['handgun']]}\n",
    "    imgData = GunDataset(dicPics = imgtextbbox, categories = cat, path = image_path, transforms = get_transform(train=False)) # Testing\n",
    "    test_img,_ = imgData[0]\n",
    "    \n",
    "    return test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cuXEF1nofu9l"
   },
   "outputs": [],
   "source": [
    "imgPath = '../Baggages/B0044'\n",
    "imgName = \"B0044_0172.png\" \n",
    "#imgName = \"gun.jpg\" \n",
    "\n",
    "image_test = image_loader(imgPath, imgName)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    prediction = loaded_model([image_test])\n",
    "\n",
    "image = Image.fromarray(image_test.mul(255).permute(1, 2,0).byte().numpy())\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "cat_rev = {cat[o]: o for o in cat}\n",
    "\n",
    "for element in range(len(prediction[0][\"boxes\"])):\n",
    "\n",
    "    boxes = prediction[0][\"boxes\"][element].cpu().numpy()\n",
    "    score = np.round(prediction[0][\"scores\"][element].cpu().numpy(), decimals= 4)\n",
    "    if score > 0.75:\n",
    "        draw.rectangle([(boxes[0], boxes[1]), (boxes[2], boxes[3])], outline =\"red\", width =3)\n",
    "        draw.text((boxes[0], boxes[1]), text = str(score)+ \" \" + cat_rev[np.int(prediction[0][\"labels\"][element])] , fill=\"#000\")\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "ObjectDetectionPytorch.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "296c1962e21f4f4081672e6bb3054067": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa6b424815754a029660856b6fac6814",
      "max": 167502836,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f923e0f54ee0426184cbe11c9cd06882",
      "value": 167502836
     }
    },
    "3f785a7cf78f4e328124fdb191ed5b72": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41a7da1582974468b550dae41b1cbcee": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9146bcaa47354f1ca72cb71a145b73c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab035faa95b24017baad2705bceb8cf5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_41a7da1582974468b550dae41b1cbcee",
      "placeholder": "​",
      "style": "IPY_MODEL_9146bcaa47354f1ca72cb71a145b73c9",
      "value": " 160M/160M [00:00&lt;00:00, 238MB/s]"
     }
    },
    "d79960d69fc54f07aeabc2718f6f9b94": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_296c1962e21f4f4081672e6bb3054067",
       "IPY_MODEL_ab035faa95b24017baad2705bceb8cf5"
      ],
      "layout": "IPY_MODEL_3f785a7cf78f4e328124fdb191ed5b72"
     }
    },
    "f923e0f54ee0426184cbe11c9cd06882": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fa6b424815754a029660856b6fac6814": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
