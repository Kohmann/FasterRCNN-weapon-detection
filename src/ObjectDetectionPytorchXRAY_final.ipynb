{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gvMwbJUh4fJZ"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "wrhFZXG38-BG",
    "outputId": "18c8e8b4-c5d8-4767-bc0c-7291c4ca077d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.isdir('pytorchObjectDetection'):\n",
    "    os.chdir('pytorchObjectDetection')\n",
    "else:\n",
    "    os.makedirs('pytorchObjectDetection')\n",
    "    os.chdir('pytorchObjectDetection')\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E5ixWRsQwpdf",
    "outputId": "eb147ab8-b758-4f60-8f5b-39cfbc22e125"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "git clone https://github.com/pytorch/vision.git\n",
    "cd vision\n",
    "git checkout v0.3.0\n",
    "cp references/detection/utils.py ../\n",
    "cp references/detection/transforms.py ../\n",
    "cp references/detection/coco_eval.py ../\n",
    "cp references/detection/engine.py ../\n",
    "cp references/detection/coco_utils.py ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jDVijTAVxF75"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pycocotools\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import pandas as pd\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "import transforms as T\n",
    "import torchvision\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "os.chdir('..')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHQc3LZZ4zCX"
   },
   "source": [
    "# Data class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gZUfIHi7xKSu"
   },
   "outputs": [],
   "source": [
    "class WeaponDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, dicPics,categories, path, transforms=None): \n",
    "        self.path = path\n",
    "        self.dicPics = dicPics\n",
    "        self.transforms = transforms\n",
    "        self.categories = categories\n",
    "        self.imgs = [o for o in dicPics]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.path +\"/\"+ self.imgs[idx]).convert(\"RGB\")        \n",
    "        box_list = self.dicPics[self.imgs[idx]][0]\n",
    "        \n",
    "        boxes = torch.as_tensor(box_list, dtype=torch.float32)\n",
    "        num_objs = len(box_list)\n",
    "        labels_list =  self.dicPics[self.imgs[idx]][1]\n",
    "\n",
    "        # multible classes\n",
    "        labels = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        for i in range(num_objs):\n",
    "          labels[i] = self.categories[labels_list[i]]\n",
    "        #print(labels)\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:,0])\n",
    "\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "        \n",
    "        return img, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nuEEAnv0v1M"
   },
   "source": [
    "### Loading train and test dictionaries stored in drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1a_wXdh5a_rV"
   },
   "outputs": [],
   "source": [
    "def load_dic(path):\n",
    "    if os.path.isfile(path):\n",
    "        return pickle.load( open( path, \"rb\" ) )\n",
    "    else:\n",
    "        print(\"no such file\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5qrp1IglZSsu",
    "outputId": "8f5082d5-c49e-4ecb-be9d-beb61e8cd2f5"
   },
   "outputs": [],
   "source": [
    "pathDataset = \"drive/MyDrive/BaggagesData\"\n",
    "pathTestDictionary = pathDataset + \"/TestDicData.pkl\"\n",
    "imgbbox_test = load_dic(pathTestDictionary)\n",
    "len(imgbbox_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z5zDnzCM408w",
    "outputId": "40babcca-c926-4d04-b038-83ec37028987"
   },
   "outputs": [],
   "source": [
    "pathTrainDictionary = pathDataset + \"/trainingdata_final.pkl\"\n",
    "imgbbox_train = load_dic(pathTrainDictionary)\n",
    "len(imgbbox_train.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ts7BvoLd6mB_",
    "outputId": "e874ef58-a8dd-4e1a-f9d4-90d71512f836"
   },
   "outputs": [],
   "source": [
    "# Counts how many boxes of each label\n",
    "\n",
    "cat = {'handgun': 1,'knife': 2, 'razorblade': 3, 'shuriken': 4}\n",
    "nr = np.zeros(4)\n",
    "for _, labels in imgbbox_train.values():\n",
    "    for l in labels:\n",
    "        nr[cat[l]-1] += 1\n",
    "nr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "70jc9ZNG48T5"
   },
   "source": [
    "#### Checks if the data was properly created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9gm_Rco3xKVq",
    "outputId": "03d47dc2-5dd3-428b-89b9-bb1e63961b55"
   },
   "outputs": [],
   "source": [
    "dataset = WeaponDataset(dicPics = imgbbox_train, categories = cat, path = pathDataset + \"/Train\", transforms = None)\n",
    "dataset.__getitem__(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x2rGfejB5WkN"
   },
   "source": [
    "#### Function to import pretrained Faster RCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "16q9Xn5_xKct"
   },
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "  # load an object detection model pre-trained on COCO\n",
    "  model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "  # get the number of input features for the classifier\n",
    "  in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "  # replace the pre-trained head with a new on\n",
    "  model.roi_heads.box_predictor = FastRCNNPredictor(in_features,num_classes)\n",
    "   \n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHSTECUl5psc"
   },
   "source": [
    "Converts image to tensor and defines transformations that will happen to the training data during learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Od8OueQUxKeV"
   },
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "   # converts the image, a PIL image, into a PyTorch Tensor\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "      # during training, randomly flip the training images\n",
    "      # and ground-truth for data augmentation\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYGb_13u7Hir"
   },
   "source": [
    "# Preperations of data and model before training takes place"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyAUeovY6Eqn"
   },
   "source": [
    "#### Defines the test and train datasets and splits them "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZwV4hFpxKhc",
    "outputId": "9c18d6b7-aa94-4755-8b16-e8bc46076097"
   },
   "outputs": [],
   "source": [
    "pathDataset_train_imgs = pathDataset + \"/Train\"\n",
    "pathDataset_test_imgs = pathDataset + \"/Test\"\n",
    "\n",
    "\n",
    "# use our dataset and defined transformations\n",
    "dataset = WeaponDataset(dicPics=imgbbox_train, categories = cat, path = pathDataset_train_imgs, transforms = get_transform(train=True))         # Training\n",
    "dataset_test = WeaponDataset(dicPics = imgbbox_test, categories = cat, path = pathDataset_test_imgs, transforms = get_transform(train=False))   # Testing\n",
    "\n",
    "# split the dataset in train and test set\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "              dataset, batch_size=6, shuffle=True, num_workers=4,\n",
    "              collate_fn=utils.collate_fn)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "         dataset_test, batch_size=1, shuffle=False, num_workers=1,\n",
    "         collate_fn=utils.collate_fn)\n",
    "\n",
    "print(\"Training set: {} examples, Test set: {} examples\".format(len(dataset), len(dataset_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LoSl68Yu6M0C"
   },
   "source": [
    "####Defines learning rate and tries to use to GPU for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5xsBOeUKxKl-",
    "outputId": "4dad3938-37a0-4900-895a-f4dbb81f559a"
   },
   "outputs": [],
   "source": [
    "print(\"Will use GPU for training:\", torch.cuda.is_available())\n",
    "import gc \n",
    "# Your code with pytorch using GPU\n",
    "gc.collect() \n",
    "numClasses = len(cat) +1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gi1vWJ-mxKk1"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# our dataset has 5 classes - weapon and background\n",
    "numClasses = len(cat) +1 \n",
    "# get the model using our helper function\n",
    "model = get_model(numClasses)\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# and a learning rate scheduler which decreases the learning rate by # 10x every 3 epochs\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UineMDsFxceo"
   },
   "source": [
    "# TRAIN NEW MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SvxLHKwtWZjl"
   },
   "outputs": [],
   "source": [
    "pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IIUC-ngQxXyc",
    "outputId": "495893d4-0f3f-4692-e9e9-bb27f81b8c2d"
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "   # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch+1, print_freq=10)\n",
    "   # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "   # evaluate on the test dataset\n",
    "    pred.append(evaluate(model, data_loader_test, device=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NbEIi83JMNon"
   },
   "source": [
    "Save model for further training or save it for good\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "2OiopzmkV5Dt",
    "outputId": "6fd74fd2-500a-4475-b06d-16338b00929d"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import io\n",
    "\n",
    "old_stdout = sys.stdout # Memorize the default stdout stream\n",
    "sys.stdout = buffer = io.StringIO()\n",
    "\n",
    "print(pred[5].summarize())\n",
    "# Call your algorithm function.\n",
    "# etc...\n",
    "\n",
    "sys.stdout = old_stdout # Put the old stream back in place\n",
    "\n",
    "whatWasPrinted = buffer.getvalue() # Return a str containing the entire contents of the buffer.\n",
    "print(whatWasPrinted) # Why not to print it?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Ui32aEGk_n0"
   },
   "outputs": [],
   "source": [
    "loss_map = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_HolposWlvh7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fYvr4UbqjUh0"
   },
   "outputs": [],
   "source": [
    "loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gu3z3unAimck"
   },
   "outputs": [],
   "source": [
    "loss.append(float(whatWasPrinted[91:96]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 572
    },
    "id": "y9xkqsI8jeqZ",
    "outputId": "215a1ac9-289d-42cb-de91-e880f03dc26b"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(5), np.array(loss))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.title(\"mAP[0.5:0.95]\")\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.plot(np.arange(5), np.array(loss_map))\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.title(\"mAP[0.5]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2nuS2h_LMNCD"
   },
   "outputs": [],
   "source": [
    "saveForGood = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1IxeW5fUMH-k"
   },
   "outputs": [],
   "source": [
    " # Saves model to folder trainedModels/XRAY\n",
    "path_trnd_model = \"drive/MyDrive/trainedModels/XRAY\"\n",
    "model_name = \"model_\" +str(len(imgbbox_train))+ \"images_\" +str(numClasses)+\"Classes_\"+str(num_epochs)+\"epochs\"\n",
    "\n",
    "if os.path.isdir(path_trnd_model) is False:\n",
    "    os.mkdir(path_trnd_model)\n",
    "\n",
    "if saveForGood:\n",
    "    # Saves the final model, not trainable anymore\n",
    "    torch.save(model.state_dict(), path_trnd_model+\"/\"+model_name + \"_finished\")\n",
    "else:\n",
    "    state = {'epoch': num_epochs +1, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict() }\n",
    "    torch.save(state, path_trnd_model+\"/\"+model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fL3PnE-Txp8T"
   },
   "source": [
    "#TRAIN OLD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PRevJETLxX4B"
   },
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer=None, filename=None):\n",
    "    # Note: Input model & optimizer should be pre-defined.  This routine only updates their states.\n",
    "    start_epoch = 0\n",
    "    if os.path.isfile(filename):\n",
    "        print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "        checkpoint = torch.load(filename)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        if optimizer is not None:\n",
    "          optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(filename, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(filename))\n",
    "\n",
    "    return model, optimizer, start_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VXZbxISzzWv8"
   },
   "source": [
    "Name and path of old model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "liu_hhULTSx7"
   },
   "outputs": [],
   "source": [
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GfY35zeLzVkn"
   },
   "outputs": [],
   "source": [
    "path_trnd_model = \"drive/MyDrive/trainedModels/XRAY\"\n",
    "model_name = \"model_1465images_11Classes_10epochs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OS9Y9ECb1Z8-",
    "outputId": "d0e08be4-70d5-4ba8-f65c-da4a8a5be4eb"
   },
   "outputs": [],
   "source": [
    "model, optimizer, start_epoch = load_checkpoint(get_model(num_classes = numClasses), optimizer, filename=path_trnd_model+\"/\"+model_name)\n",
    "model = model.to(device)\n",
    "\n",
    "gc.collect() \n",
    "# individually transfer the optimizer parts...\n",
    "for state in optimizer.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jd6jmP73xKgU",
    "outputId": "387bb7c2-371f-40b1-b317-661706cc1ff8"
   },
   "outputs": [],
   "source": [
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch+1, print_freq=10)\n",
    "\n",
    "    # update the learning rate\n",
    "    lr_scheduler.step()\n",
    "   # evaluate on the test dataset\n",
    "    evaluate(model, data_loader_test, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fLAn2yNg2kb_"
   },
   "source": [
    "Save model for further training or save it for good\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i6xktKcG2pyp"
   },
   "outputs": [],
   "source": [
    "saveForGood = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CGy3mL31x0-6"
   },
   "outputs": [],
   "source": [
    " # Saves model to folder trainedModels/XRAY\n",
    "path_trnd_model = \"drive/MyDrive/trainedModels/XRAY\"\n",
    "model_name = \"model_\" +str(len(imgbbox_train))+ \"images_\" +str(numClasses)+\"Classes_\"+str(start_epoch+num_epochs-1 )+\"epochs\"\n",
    "\n",
    "if os.path.isdir(path_trnd_model) is False:\n",
    "    os.mkdir(path_trnd_model)\n",
    "\n",
    "if saveForGood:\n",
    "    # Saves the final model, not trainable anymore\n",
    "    torch.save(model.state_dict(), path_trnd_model+\"/\"+model_name + \"_finished\")\n",
    "else:\n",
    "    state = {'epoch': num_epochs +1, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict() }\n",
    "    torch.save(state, path_trnd_model+\"/\"+model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Yb-GeFPx6KK"
   },
   "source": [
    "#PREDICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "53641b903ab448e8bf63890cd70ca93f",
      "9f1c9efccc00485ebad6e580e898566c",
      "9c3960f0929a471ba4b53ab910658bcf",
      "cb77f3461f8a4a9ba7a483897c13f4e2",
      "a12614b2fb904decb281e5540642075d",
      "082877c47f694f599e779ae62a7497de",
      "70b2d1f07f3d443aa6d43f8268e1a7c9",
      "e4bee9e5a25244ec8d97a5845a94217b"
     ]
    },
    "id": "4VcmX8rOx1Iv",
    "outputId": "8c1a5de7-38b7-4ec7-81b9-8d0e0c81f412"
   },
   "outputs": [],
   "source": [
    "# To load trained model\n",
    "path_trnd_model = \"drive/MyDrive/trainedModels/XRAY\"\n",
    "model_name =\"model_1465images_5Classes_5epochs_finished\"\n",
    "\n",
    "loaded_model = get_model(num_classes = len(cat) +1 )\n",
    "\n",
    "if os.path.isfile(path_trnd_model +\"/\"+ model_name):\n",
    "    loaded_model.load_state_dict(torch.load( path_trnd_model +\"/\"+ model_name))\n",
    "else:\n",
    "    print(\"Wrong path or filename\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5rPHd2axbMPF",
    "outputId": "69bff8f3-f2cc-4396-9c7f-48234bbc17a4"
   },
   "outputs": [],
   "source": [
    "evaluator = evaluate(model, data_loader_test, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kCgE4RpMljHR",
    "outputId": "285bdaf6-88a2-432e-b931-c8822ff0a603"
   },
   "outputs": [],
   "source": [
    "gc.collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 345
    },
    "id": "QIf9od_5dKs2",
    "outputId": "2d84aada-2abf-47ae-d23e-b00d5441d87b"
   },
   "outputs": [],
   "source": [
    "torch.set_num_threads(1)\n",
    "#device = torch.device('cpu')\n",
    "device = torch.device('cuda')\n",
    "\n",
    "\n",
    "loaded_model.to(device)\n",
    "loaded_model.eval()\n",
    "\n",
    "predictions = []\n",
    "#image, _ = next(iter(data_loader_test))\n",
    "\n",
    "for image, targets in data_loader_test:\n",
    "    image = list(img.to(device) for img in image)\n",
    "\n",
    "    #torch.cuda.synchronize()\n",
    "    predictions.append(loaded_model(image) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vCkr57Tjmzgf",
    "outputId": "169d3c8e-cdb6-41db-e49c-1493124d5966"
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XlS3Hy-5x1Kf"
   },
   "outputs": [],
   "source": [
    "idx = 20\n",
    "#for idx in range(1):\n",
    "\n",
    "cat_color = {1:\"red\", 2:\"yellow\", 3: \"blue\", 4:\"orange\"}\n",
    "\n",
    "img, _ = dataset_test[idx]\n",
    "\n",
    "label_boxes = np.array(dataset_test[idx][1][\"boxes\"])\n",
    "#put the model in evaluation mode\n",
    "loaded_model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = loaded_model([img])\n",
    "image = Image.fromarray(img.mul(255).permute(1, 2,0).byte().numpy())\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "cat_rev = {cat[o]: o for o in cat}\n",
    "\n",
    "# draw groundtruth\n",
    "for elem in range(len(label_boxes)):\n",
    "    draw.rectangle([(label_boxes[elem][0], label_boxes[elem][1]),\n",
    "    (label_boxes[elem][2], label_boxes[elem][3])], \n",
    "    outline =\"green\", width =3)\n",
    "    \n",
    "for element in range(len(prediction[0][\"boxes\"])):\n",
    "\n",
    "    boxes = prediction[0][\"boxes\"][element].cpu().numpy()\n",
    "    score = np.round(prediction[0][\"scores\"][element].cpu().numpy(),\n",
    "                    decimals= 4)\n",
    "    if score > 0.8:\n",
    "\n",
    "        draw.rectangle([(boxes[0], boxes[1]), (boxes[2], boxes[3])], outline =cat_color[np.int(prediction[0][\"labels\"][element])], width =3)\n",
    "        draw.text((boxes[0], boxes[1]), text = str(score)+ \" \" + cat_rev[np.int(prediction[0][\"labels\"][element])] , fill=\"#000\")\n",
    "display(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DxNxWfu_TdYf"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for idx in range(len(dataset_test)):\n",
    "\n",
    "    cat_color = {1:\"red\", 2:\"yellow\", 3: \"blue\", 4:\"orange\"}\n",
    "\n",
    "    img, _ = dataset_test[idx]\n",
    "\n",
    "    label_boxes = np.array(dataset_test[idx][1][\"boxes\"])\n",
    "    #put the model in evaluation mode\n",
    "    loaded_model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = loaded_model([img])\n",
    "    image = Image.fromarray(img.mul(255).permute(1, 2,0).byte().numpy())\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    cat_rev = {cat[o]: o for o in cat}\n",
    "\n",
    "    # draw groundtruth\n",
    "    #for elem in range(len(label_boxes)):\n",
    "    #    draw.rectangle([(label_boxes[elem][0], label_boxes[elem][1]),\n",
    "    #    (label_boxes[elem][2], label_boxes[elem][3])], \n",
    "    #    outline =\"green\", width =2)\n",
    "        \n",
    "    for element in range(len(prediction[0][\"boxes\"])):\n",
    "\n",
    "        boxes = prediction[0][\"boxes\"][element].cpu().numpy()\n",
    "        score = np.round(prediction[0][\"scores\"][element].cpu().numpy(),\n",
    "                        decimals= 4)\n",
    "        if score > 0.7:\n",
    "\n",
    "            draw.rectangle([(boxes[0], boxes[1]), (boxes[2], boxes[3])], outline =cat_color[np.int(prediction[0][\"labels\"][element])], width =3)\n",
    "            draw.text((boxes[0], boxes[1]), text = str(score)+ \" \" + cat_rev[np.int(prediction[0][\"labels\"][element])] , fill=\"#000\")\n",
    "    display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_wE3wLXZZK8C"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "0nuEEAnv0v1M",
    "UineMDsFxceo"
   ],
   "name": "ObjectDetectionPytorchXRAY.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "082877c47f694f599e779ae62a7497de": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "53641b903ab448e8bf63890cd70ca93f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9c3960f0929a471ba4b53ab910658bcf",
       "IPY_MODEL_cb77f3461f8a4a9ba7a483897c13f4e2"
      ],
      "layout": "IPY_MODEL_9f1c9efccc00485ebad6e580e898566c"
     }
    },
    "70b2d1f07f3d443aa6d43f8268e1a7c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9c3960f0929a471ba4b53ab910658bcf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_082877c47f694f599e779ae62a7497de",
      "max": 167502836,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a12614b2fb904decb281e5540642075d",
      "value": 167502836
     }
    },
    "9f1c9efccc00485ebad6e580e898566c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a12614b2fb904decb281e5540642075d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cb77f3461f8a4a9ba7a483897c13f4e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4bee9e5a25244ec8d97a5845a94217b",
      "placeholder": "​",
      "style": "IPY_MODEL_70b2d1f07f3d443aa6d43f8268e1a7c9",
      "value": " 160M/160M [00:16&lt;00:00, 10.2MB/s]"
     }
    },
    "e4bee9e5a25244ec8d97a5845a94217b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
