{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ObjectDetectionPytorchWeapons.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "7ax6rbjcpFlP"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMmgkneXpFlM"
      },
      "source": [
        "import os\n",
        "import pycocotools\n",
        "os.getcwd()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOiAek98pcnN"
      },
      "source": [
        "%%bash\n",
        "git clone https://github.com/pytorch/vision.git\n",
        "cd vision\n",
        "git checkout v0.3.0\n",
        "cp references/detection/utils.py ../\n",
        "cp references/detection/transforms.py ../\n",
        "cp references/detection/coco_eval.py ../\n",
        "cp references/detection/engine.py ../\n",
        "cp references/detection/coco_utils.py ../"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLYciXRvppYM"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from PIL import Image\n",
        "from PIL import ImageDraw\n",
        "import pandas as pd\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "import transforms as T\n",
        "import torchvision\n",
        "import xml.etree.ElementTree as ET\n",
        "import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akEhpNBwpFlN"
      },
      "source": [
        "def extract_BBoxes(filename):\n",
        "   \n",
        "    root = ET.parse(filename).getroot()\n",
        "    \n",
        "    boxes = list()\n",
        "    names = list()\n",
        "    for objct in root.findall(\".//object\"):\n",
        "        name = objct.find('name').text\n",
        "        xmin = int(objct.find('bndbox/xmin').text)\n",
        "        ymin = int(objct.find('bndbox/ymin').text)\n",
        "        xmax = int(objct.find('bndbox/xmax').text)\n",
        "        ymax = int(objct.find('bndbox/ymax').text)\n",
        "        names.append(name)\n",
        "        boxes.append([xmin,ymin,xmax,ymax])\n",
        "\n",
        "    return [boxes,names]\n",
        "    \n",
        "def load_dataset(path, deleteFiles = False):\n",
        "    files_xml = [f for f in glob.glob(path + \"/*.xml\")] # comes in random order\n",
        "\n",
        "    \n",
        "    imgbbox = dict()\n",
        "    print(len(files_xml))\n",
        "    for file in files_xml:  \n",
        "        \n",
        "        imgFilePath = file[:-3] + \"jpg\"\n",
        "        if os.path.exists(imgFilePath):  \n",
        "            lbl_bbox = extract_BBoxes(file)  # Gets the bbox information\n",
        "            \n",
        "            #print(lbl_bbox[0])\n",
        "            \n",
        "            imgbbox.update({imgFilePath.replace(path+\"/\",''): lbl_bbox})\n",
        "            \n",
        "        elif deleteFiles:\n",
        "            print(\"Found xml with no jpg\")\n",
        "            print(\"Deleting xml file: %s\" %file)\n",
        "            os.remove(file)\n",
        "            print(\"Deleted\")\n",
        "\n",
        "    return imgbbox"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVlv1ihLqzr8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "pathDataset = 'drive/MyDrive/Project2'\n",
        "imgbbox = load_dataset(pathDataset, deleteFiles=False)\n",
        "imgbbox['2 (20).jpg']\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZad7ZIgrhLN"
      },
      "source": [
        "Obtaining the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5t_Hw-HvrzM6"
      },
      "source": [
        "Class containing all data for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDaSI_dsrki-"
      },
      "source": [
        "class GunDataset(torch.utils.data.Dataset):\n",
        "    \n",
        "    def __init__(self, dicPics,categories, path, transforms=None): \n",
        "        self.path = path\n",
        "        self.dicPics = dicPics\n",
        "        self.transforms = transforms\n",
        "        self.categories = categories\n",
        "        self.imgs = [o for o in dicPics]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.path +\"/\"+ self.imgs[idx]).convert(\"RGB\")        \n",
        "        box_list = self.dicPics[self.imgs[idx]][0]\n",
        "        \n",
        "        boxes = torch.as_tensor(box_list, dtype=torch.float32)\n",
        "        num_objs = len(box_list)\n",
        "        labels_list =  self.dicPics[self.imgs[idx]][1]\n",
        "\n",
        "        # there is only one class\n",
        "        #labels = torch.ones((num_objs,), dtype=torch.int64) \n",
        "\n",
        "        # multible classes\n",
        "        labels = torch.zeros((num_objs,), dtype=torch.int64)\n",
        "\n",
        "        for i in range(num_objs):\n",
        "          labels[i] = self.categories[labels_list[i]]\n",
        "        \n",
        "        image_id = torch.tensor([idx])\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:,0])\n",
        "\n",
        "        # suppose all instances are not crowd\n",
        "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"image_id\"] = image_id\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = iscrowd\n",
        "        \n",
        "        if self.transforms is not None:\n",
        "            img, target = self.transforms(img, target)\n",
        "        \n",
        "        return img, target\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4f50oQXtcpr"
      },
      "source": [
        "Checks if the class is correct and returns the expected values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EyrKUsKsFlU"
      },
      "source": [
        "cat = {'handgun': 1,'rifle': 2}\n",
        "dataset = GunDataset(dicPics = imgbbox,categories = cat, path = pathDataset, transforms = None) #, categories = cat\n",
        "dataset.__getitem__(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiKnyvGO0h3I"
      },
      "source": [
        "image = Image.open(pathDataset + '/1 (107).jpg')\n",
        "image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vByvVLARtk8q"
      },
      "source": [
        "Downloads and configures the model for our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdcuDZgAsM4R"
      },
      "source": [
        "def get_model(num_classes):\n",
        "  # load an object detection model pre-trained on COCO\n",
        "  model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "  # get the number of input features for the classifier\n",
        "  in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "  # replace the pre-trained head with a new on\n",
        "  model.roi_heads.box_predictor = FastRCNNPredictor(in_features,num_classes)\n",
        "   \n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWKIW6W8t33m"
      },
      "source": [
        "def get_transform(train):\n",
        "    transforms = []\n",
        "   # converts the image, a PIL image, into a PyTorch Tensor\n",
        "    transforms.append(T.ToTensor())\n",
        "    if train:\n",
        "      # during training, randomly flip the training images\n",
        "      # and ground-truth for data augmentation\n",
        "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
        "    return T.Compose(transforms)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51-JXik-uAlG"
      },
      "source": [
        "# use our dataset and defined transformations\n",
        "dataset = GunDataset(dicPics=imgbbox, categories = cat, path = pathDataset, transforms = get_transform(train=True))      # Training\n",
        "dataset_test = GunDataset(dicPics = imgbbox, categories = cat, path = pathDataset, transforms = get_transform(train=False)) # Testing\n",
        "\n",
        "# split the dataset in train and test set\n",
        "torch.manual_seed(1)\n",
        "indices = torch.randperm(len(dataset)).tolist()\n",
        "dataset = torch.utils.data.Subset(dataset, indices[:-40])  \n",
        "#dataset = torch.utils.data.Subset(dataset, indices[:100])  # testing\n",
        "\n",
        "dataset_test = torch.utils.data.Subset(dataset_test, indices[-40:])\n",
        "#dataset_test = torch.utils.data.Subset(dataset_test, indices[-30:])\n",
        "\n",
        "\n",
        "# define training and validation data loaders\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "              dataset, batch_size=8, shuffle=True, num_workers=4,\n",
        "              collate_fn=utils.collate_fn)\n",
        "\n",
        "data_loader_test = torch.utils.data.DataLoader(\n",
        "         dataset_test, batch_size=1, shuffle=False, num_workers=4,\n",
        "         collate_fn=utils.collate_fn)\n",
        "\n",
        "print(\"We have: {} examples, {} are training and {} testing\".format(len(indices), len(dataset), len(dataset_test)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CD6I0fXyuilM"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgjqrxZeu3gH"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# our dataset has two classes only - gun and not gun\n",
        "num_classes = 3\n",
        "# get the model using our helper function\n",
        "model = get_model(num_classes)\n",
        "# move model to the right device\n",
        "model.to(device)\n",
        "# construct an optimizer\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "# and a learning rate scheduler which decreases the learning rate by # 10x every 3 epochs\n",
        "\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b-LLxtupFlP"
      },
      "source": [
        "## TRAIN NEW MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNA-M_2bwNiW"
      },
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "   # train for one epoch, printing every 10 iterations\n",
        "    train_one_epoch(model, optimizer, data_loader, device, epoch+1, print_freq=10)\n",
        "   # update the learning rate\n",
        "\n",
        "    lr_scheduler.step()\n",
        "   # evaluate on the test dataset\n",
        "    evaluate(model, data_loader_test, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pc01-dAC3lgJ"
      },
      "source": [
        " # Saves model to folder trainedModels\n",
        "    \n",
        "path_trnd_model = \"drive/MyDrive/trainedModels\"\n",
        "if os.path.isdir(path_trnd_model) is False:\n",
        "    os.mkdir(path_trnd_model)\n",
        "\n",
        "state = {'epoch': num_epochs +1, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict() }\n",
        "torch.save(state, path_trnd_model+\"/model_3Classes_15epochs\")\n",
        "\n",
        "#torch.save(model.state_dict(), )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ax6rbjcpFlP"
      },
      "source": [
        "## TRAIN OLD MODEL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6swBoWihpFlP"
      },
      "source": [
        "def load_checkpoint(model, optimizer=None, filename=None):\n",
        "    # Note: Input model & optimizer should be pre-defined.  This routine only updates their states.\n",
        "    start_epoch = 0\n",
        "    if os.path.isfile(filename):\n",
        "        print(\"=> loading checkpoint '{}'\".format(filename))\n",
        "        checkpoint = torch.load(filename)\n",
        "        start_epoch = checkpoint['epoch']\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        if optimizer is not None:\n",
        "          optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(filename, checkpoint['epoch']))\n",
        "    else:\n",
        "        print(\"=> no checkpoint found at '{}'\".format(filename))\n",
        "\n",
        "    return model, optimizer, start_epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJmsgJ52pFlP"
      },
      "source": [
        "path_trnd_model = \"drive/MyDrive/trainedModels\"\n",
        "model, optimizer, start_epoch = load_checkpoint(get_model(num_classes = 3), optimizer, filename=path_trnd_model+\"/model_3Classes_15epochs\")\n",
        "model = model.to(device)\n",
        "\n",
        "# individually transfer the optimizer parts...\n",
        "for state in optimizer.state.values():\n",
        "    for k, v in state.items():\n",
        "        if isinstance(v, torch.Tensor):\n",
        "            state[k] = v.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2euKDbwpFlP"
      },
      "source": [
        "# let's train it for 0 epochs\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "   # train for one epoch, printing every 10 iterations\n",
        "    train_one_epoch(model, optimizer, data_loader, device, epoch+1, print_freq=10)\n",
        "# update the learning rate\n",
        "\n",
        "    lr_scheduler.step()\n",
        "   # evaluate on the test dataset\n",
        "    evaluate(model, data_loader_test, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mglK4EjwpFlP"
      },
      "source": [
        "state = {'epoch': num_epochs +1, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict() }\n",
        "torch.save(state, path_trnd_model+\"/model_3Classes_15epochs\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4Z8izKKmi-9"
      },
      "source": [
        "# Saves the final model, not trainable anymore\n",
        "#torch.save(model.state_dict(), path_trnd_model+\"/model_3Classes_15epochs_finished\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjmH7dJmpFlP"
      },
      "source": [
        "# PREDICT "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC_akS85pFlP"
      },
      "source": [
        "# To load trained model\n",
        "model_name = \"model_3Classes_20epochs_finished\"\n",
        "\n",
        "loaded_model = get_model(num_classes = 3)\n",
        "\n",
        "if os.path.isfile(path_trnd_model +\"/\"+ model_name):\n",
        "    loaded_model.load_state_dict(torch.load( path_trnd_model +\"/\"+ model_name))\n",
        "else:\n",
        "    print(\"Wrong path or filename\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rlaPAHag34ee"
      },
      "source": [
        "loaded_model = model\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        "#loaded_model.to(device)\n",
        "cat_color = {1:\"yellow\", 2:\"orange\"}\n",
        "\n",
        "for idx in range(len(dataset_test)):\n",
        "    img, _ = dataset_test[idx]\n",
        "    label_boxes = np.array(dataset_test[idx][1][\"boxes\"])\n",
        "    #put the model in evaluation mode\n",
        "    loaded_model.eval()\n",
        "    with torch.no_grad():\n",
        "        prediction = loaded_model([img.to(device)])\n",
        "\n",
        "    image = Image.fromarray(img.mul(255).permute(1, 2,0).byte().numpy())\n",
        "    draw = ImageDraw.Draw(image)\n",
        "\n",
        "    cat_rev = {cat[o]: o for o in cat}\n",
        "    # draw groundtruth\n",
        "    for elem in range(len(label_boxes)):\n",
        "        draw.rectangle([(label_boxes[elem][0], label_boxes[elem][1]),\n",
        "        (label_boxes[elem][2], label_boxes[elem][3])], \n",
        "        outline =\"green\", width =3)\n",
        "        \n",
        "    for element in range(len(prediction[0][\"boxes\"])):\n",
        "\n",
        "        boxes = prediction[0][\"boxes\"][element].cpu().numpy()\n",
        "        score = np.round(prediction[0][\"scores\"][element].cpu().numpy(),\n",
        "                        decimals= 4)\n",
        "        if score > 0.8:\n",
        "            draw.rectangle([(boxes[0], boxes[1]), (boxes[2], boxes[3])], outline =cat_color[np.int(prediction[0][\"labels\"][element])], width =3)\n",
        "            draw.text((boxes[0], boxes[1]), text = str(score)+ \" \" + cat_rev[np.int(prediction[0][\"labels\"][element])] , fill=\"#000\")\n",
        "    display(image)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cuXEF1nofu9l"
      },
      "source": [
        "pred_list_labels = []\n",
        "gt_list_labels = []\n",
        "\n",
        "\n",
        "for idx in range(len(dataset_test)):\n",
        "\n",
        "    gt_lab = np.array([])\n",
        "    img, targets = dataset_test[idx]\n",
        "    \n",
        "    if len(targets) is not 0:\n",
        "        gt_lab = targets[\"labels\"].numpy()\n",
        "    gt_list_labels.append(gt_lab)\n",
        "        \n",
        "    with torch.no_grad():\n",
        "        prediction = loaded_model([img.to(device)])[0]\n",
        "\n",
        "\n",
        "    pred_list_labels.append(prediction[\"labels\"].cpu().numpy()[prediction[\"scores\"].cpu().numpy() > 0.8])\n",
        "    \n",
        "    if (idx+1) % 5 == 0:\n",
        "        print(idx+1, \"/\", len(dataset_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgCDsOGHn4Hr"
      },
      "source": [
        "labels = {cat[o]: o for o in cat}\n",
        "\n",
        "TP, FP, FN, TN = 0, 0, 0, 0\n",
        "\n",
        "for idx in range(len(dataset_test)):\n",
        "    gt_labels = gt_list_labels[idx]\n",
        "    pred_labels = pred_list_labels[idx]\n",
        "    \n",
        "    if  (gt_labels.any()  == True  and pred_labels.any() == True):\n",
        "        TP += 1\n",
        "    elif (gt_labels.any() == False and pred_labels.any() == True):\n",
        "        FP += 1\n",
        "    elif (gt_labels.any() == True  and pred_labels.any() == False):\n",
        "        FN += 1\n",
        "    elif (gt_labels.any() == False and pred_labels.any() == False):\n",
        "        TN += 1\n",
        "    \n",
        "\n",
        "print(\"\\nTP: {}, FP: {}, FN: {}, TN: {}  |  Accuracy: {:.4f},  Precision: {:.3f},  Recall: {:.3f}\".format(\n",
        "                                                       TP,FP,FN,TN,((TP+TN)/(FP+FN+TP+TN)), TP/(TP+FP), TP/(TP+FN) )) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwgrrOkQoP64"
      },
      "source": [
        "labels = {cat[o]: o for o in cat}\n",
        "tp, tn, fp, fn = np.zeros(len(labels)), np.zeros(len(labels)), np.zeros(len(labels)), np.zeros(len(labels))\n",
        "\n",
        "for idx in range(1,len(dataset_test)):\n",
        "    gt_labels = gt_list_labels[idx]\n",
        "    pred_labels = pred_list_labels[idx]\n",
        "    \n",
        "    count_gt, count_pred = np.zeros(len(labels)), np.zeros(len(labels))\n",
        "    \n",
        "    for label in gt_labels:\n",
        "        count_gt[label-1] += 1\n",
        "    for label in pred_labels:\n",
        "        count_pred[label-1] += 1\n",
        "        \n",
        "    #print(\"\\t\\t\", count_gt,\"\\t\", count_pred, \"\\n\")\n",
        "    \n",
        "\n",
        "    \n",
        "    for i in range(len(labels)):\n",
        "        difference = count_pred[i] - count_gt[i]\n",
        "        \n",
        "        if difference == 0:\n",
        "            tp[i] += count_pred[i]\n",
        "            if count_pred[i] == 0 and count_gt[i] == 0:\n",
        "                tn[i] += 1\n",
        "        elif difference > 0:\n",
        "            tp[i] += count_gt[i]\n",
        "            fp[i] += difference\n",
        "\n",
        "        else:\n",
        "            tp[i] += count_pred[i]\n",
        "            fn[i] -= difference\n",
        "\n",
        "# print statistics\n",
        "for i in range(len(labels)):\n",
        "    print()\n",
        "    print(\"{}\\tTP: {}, FP: {}, FN: {};\\t   |  Precision: {:.3f},  Recall: {:.3f}\".format(\n",
        "        labels[i+1] + \"   \", tp[i] ,fp[i], fn[i], tp[i]/(tp[i]+fp[i]), tp[i]/(tp[i]+fn[i]) ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKFUiWGFo0o8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}