{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BMmgkneXpFlM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "if os.path.isdir('pytorchObjectDetection'):\n",
    "    os.chdir('pytorchObjectDetection')\n",
    "else:\n",
    "    os.makedirs('pytorchObjectDetection')\n",
    "    os.chdir('pytorchObjectDetection')\n",
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hOiAek98pcnN"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "git clone https://github.com/pytorch/vision.git\n",
    "cd vision\n",
    "git checkout v0.3.0\n",
    "cp references/detection/utils.py ../\n",
    "cp references/detection/transforms.py ../\n",
    "cp references/detection/coco_eval.py ../\n",
    "cp references/detection/engine.py ../\n",
    "cp references/detection/coco_utils.py ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vLYciXRvppYM"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pycocotools\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import pandas as pd\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "import transforms as T\n",
    "import torchvision\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extracts bounding box and label from images to create a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "akEhpNBwpFlN"
   },
   "outputs": [],
   "source": [
    "def extract_BBoxes(filename):\n",
    "   \n",
    "    root = ET.parse(filename).getroot()\n",
    "    \n",
    "    boxes = list()\n",
    "    names = list()\n",
    "    for objct in root.findall(\".//object\"):\n",
    "        name = objct.find('name').text\n",
    "        xmin = int(objct.find('bndbox/xmin').text)\n",
    "        ymin = int(objct.find('bndbox/ymin').text)\n",
    "        xmax = int(objct.find('bndbox/xmax').text)\n",
    "        ymax = int(objct.find('bndbox/ymax').text)\n",
    "        names.append(name)\n",
    "        boxes.append([xmin,ymin,xmax,ymax])\n",
    "\n",
    "    return [boxes,names]\n",
    "    \n",
    "def load_dataset(path, deleteFiles = False):\n",
    "    files_xml = [f for f in glob.glob(path + \"/*.xml\")] # comes in random order\n",
    "\n",
    "    \n",
    "    imgbbox = dict()\n",
    "    print(len(files_xml))\n",
    "    for file in files_xml:  \n",
    "        \n",
    "        imgFilePath = file[:-3] + \"jpg\"\n",
    "        if os.path.exists(imgFilePath):  \n",
    "            lbl_bbox = extract_BBoxes(file)  # Gets the bbox information\n",
    "            \n",
    "            #print(lbl_bbox[0])\n",
    "            \n",
    "            imgbbox.update({imgFilePath.replace(path+\"/\",''): lbl_bbox})\n",
    "            \n",
    "        elif deleteFiles:\n",
    "            print(\"Found xml with no jpg\")\n",
    "            print(\"Deleting xml file: %s\" %file)\n",
    "            os.remove(file)\n",
    "            print(\"Deleted\")\n",
    "\n",
    "    return imgbbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iVlv1ihLqzr8"
   },
   "outputs": [],
   "source": [
    "pathDataset = '../Project2' # folder to images\n",
    "imgbbox = load_dataset(pathDataset, deleteFiles=False) # creates dictionary\n",
    "imgbbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5t_Hw-HvrzM6"
   },
   "source": [
    "## Data Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BDaSI_dsrki-"
   },
   "outputs": [],
   "source": [
    "class GunDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, dicPics,categories, path, transforms=None): \n",
    "        self.path = path\n",
    "        self.dicPics = dicPics\n",
    "        self.transforms = transforms\n",
    "        self.categories = categories\n",
    "        self.imgs = [o for o in dicPics]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.path +\"/\"+ self.imgs[idx]).convert(\"RGB\")        \n",
    "        box_list = self.dicPics[self.imgs[idx]][0]\n",
    "        \n",
    "        boxes = torch.as_tensor(box_list, dtype=torch.float32)\n",
    "        num_objs = len(box_list)\n",
    "        labels_list =  self.dicPics[self.imgs[idx]][1]\n",
    "\n",
    "        # multible classes\n",
    "        labels = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        for i in range(num_objs):\n",
    "            labels[i] = self.categories[labels_list[i]]\n",
    "        \n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:,0])\n",
    "\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "        \n",
    "        return img, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U4f50oQXtcpr"
   },
   "source": [
    "Checks if the class is correct and returns the expected values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9EyrKUsKsFlU"
   },
   "outputs": [],
   "source": [
    "cat = {'handgun': 1,'rifle': 2}\n",
    "dataset = GunDataset(dicPics = imgbbox,categories = cat, path = pathDataset, transforms = None) #, categories = cat\n",
    "dataset.__getitem__(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vByvVLARtk8q"
   },
   "source": [
    "### Downloads and configures the model for our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BdcuDZgAsM4R"
   },
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "  # load an object detection model pre-trained on COCO\n",
    "  model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "  # get the number of input features for the classifier\n",
    "  in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "  # replace the pre-trained head with a new on\n",
    "  model.roi_heads.box_predictor = FastRCNNPredictor(in_features,num_classes)\n",
    "   \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tWKIW6W8t33m"
   },
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "   # converts the image, a PIL image, into a PyTorch Tensor\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "      # during training, randomly flip the training images\n",
    "      # and ground-truth for data augmentation\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "51-JXik-uAlG"
   },
   "outputs": [],
   "source": [
    "# use our dataset and defined transformations\n",
    "dataset = GunDataset(dicPics=imgbbox, categories = cat, path = pathDataset, transforms = get_transform(train=True))      # Training\n",
    "dataset_test = GunDataset(dicPics = imgbbox, categories = cat, path = pathDataset, transforms = get_transform(train=False)) # Testing\n",
    "\n",
    "# split the dataset in train and test set\n",
    "torch.manual_seed(1)\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indices[:-40])  \n",
    "#dataset = torch.utils.data.Subset(dataset, indices[:100])  # testing\n",
    "\n",
    "dataset_test = torch.utils.data.Subset(dataset_test, indices[-40:])\n",
    "#dataset_test = torch.utils.data.Subset(dataset_test, indices[-30:])\n",
    "\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "              dataset, batch_size=8, shuffle=True, num_workers=4,\n",
    "              collate_fn=utils.collate_fn)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(\n",
    "         dataset_test, batch_size=1, shuffle=False, num_workers=4,\n",
    "         collate_fn=utils.collate_fn)\n",
    "\n",
    "print(\"We have: {} examples, {} are training and {} testing\".format(len(indices), len(dataset), len(dataset_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CD6I0fXyuilM"
   },
   "outputs": [],
   "source": [
    "print(\"Will use GPU for training:\", torch.cuda.is_available())\n",
    "import gc \n",
    "# Created more space for images when training in batches\n",
    "gc.collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qgjqrxZeu3gH"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# our dataset has three classes only - gun,rifle and background\n",
    "numClasses = len(cat) +1 # get the model using our helper function\n",
    "model = get_model(numClasses)\n",
    "# move model to the right device\n",
    "model.to(device)\n",
    "# construct an optimizer\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "# and a learning rate scheduler which decreases the learning rate by # 10x every 3 epochs\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0b-LLxtupFlP"
   },
   "source": [
    "## TRAIN NEW MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fNA-M_2bwNiW"
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "   # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch+1, print_freq=10)\n",
    "   # update the learning rate\n",
    "\n",
    "    lr_scheduler.step()\n",
    "   # evaluate on the test dataset\n",
    "    evaluate(model, data_loader_test, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Save model for further training or save it for good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveForGood = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves model to folder trainedModels/Gun\n",
    "path_trnd_model = \"drive/MyDrive/trainedModels/Gun\"\n",
    "model_name = \"model_\" +str(len(imgbbox_train))+ \"images_\" +str(numClasses)+\"Classes_\"+str(start_epoch+num_epochs-1 )+\"epochs\"\n",
    "\n",
    "if os.path.isdir(path_trnd_model) is False:\n",
    "    os.mkdir(path_trnd_model)\n",
    "\n",
    "if saveForGood:\n",
    "    # Saves the final model, not trainable anymore\n",
    "    torch.save(model.state_dict(), path_trnd_model+\"/\"+model_name + \"_finished\")\n",
    "else:\n",
    "    state = {'epoch': num_epochs +1, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict() }\n",
    "    torch.save(state, path_trnd_model+\"/\"+model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ax6rbjcpFlP"
   },
   "source": [
    "## TRAIN OLD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6swBoWihpFlP"
   },
   "outputs": [],
   "source": [
    "def load_checkpoint(model, optimizer=None, filename=None): # loads a model for further training\n",
    "\n",
    "    start_epoch = 0\n",
    "    if os.path.isfile(filename):\n",
    "        print(\"=> loading checkpoint '{}'\".format(filename))\n",
    "        checkpoint = torch.load(filename)\n",
    "        start_epoch = checkpoint['epoch']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        if optimizer is not None:\n",
    "            optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(filename, checkpoint['epoch']))\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(filename))\n",
    "\n",
    "    return model, optimizer, start_epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name and path of old model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tJmsgJ52pFlP"
   },
   "outputs": [],
   "source": [
    "path_trnd_model = \"drive/MyDrive/trainedModels\"\n",
    "model, optimizer, start_epoch = load_checkpoint(get_model(num_classes = 3), optimizer, filename=path_trnd_model+\"/model_3Classes_15epochs\")\n",
    "model = model.to(device)\n",
    "\n",
    "# individually transfer the optimizer parts...\n",
    "for state in optimizer.state.values():\n",
    "    for k, v in state.items():\n",
    "        if isinstance(v, torch.Tensor):\n",
    "            state[k] = v.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F2euKDbwpFlP"
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "   # train for one epoch, printing every 10 iterations\n",
    "    train_one_epoch(model, optimizer, data_loader, device, epoch+1, print_freq=10)\n",
    "# update the learning rate\n",
    "\n",
    "    lr_scheduler.step()\n",
    "   # evaluate on the test dataset\n",
    "    evaluate(model, data_loader_test, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveForGood = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saves model to folder trainedModels/Gun\n",
    "path_trnd_model = \"drive/MyDrive/trainedModels/Gun\"\n",
    "model_name = \"model_\" +str(len(imgbbox_train))+ \"images_\" +str(numClasses)+\"Classes_\"+str(start_epoch+num_epochs-1 )+\"epochs\"\n",
    "\n",
    "if os.path.isdir(path_trnd_model) is False:\n",
    "    os.mkdir(path_trnd_model)\n",
    "\n",
    "if saveForGood:\n",
    "    # Saves the final model, not trainable anymore\n",
    "    torch.save(model.state_dict(), path_trnd_model+\"/\"+model_name + \"_finished\")\n",
    "else:\n",
    "    state = {'epoch': num_epochs +1, 'state_dict': model.state_dict(), 'optimizer': optimizer.state_dict() }\n",
    "    torch.save(state, path_trnd_model+\"/\"+model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### continue to prediction.ipynb for testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "7ax6rbjcpFlP"
   ],
   "name": "ObjectDetectionPytorchWeapons.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
