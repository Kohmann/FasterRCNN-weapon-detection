{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../pytorchObjectDetection\")\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pycocotools\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import pandas as pd\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "import transforms as T\n",
    "import torchvision\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "os.chdir('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeaponDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, dicPics,categories, path, transforms=None): \n",
    "        self.path = path\n",
    "        self.dicPics = dicPics\n",
    "        self.transforms = transforms\n",
    "        self.categories = categories\n",
    "        self.imgs = [o for o in dicPics]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.path +\"/\"+ self.imgs[idx]).convert(\"RGB\")        \n",
    "        box_list = self.dicPics[self.imgs[idx]][0]\n",
    "        \n",
    "        boxes = torch.as_tensor(box_list, dtype=torch.float32)\n",
    "        num_objs = len(box_list)\n",
    "        labels_list =  self.dicPics[self.imgs[idx]][1]\n",
    "\n",
    "        # there is only one class\n",
    "        #labels = torch.ones((num_objs,), dtype=torch.int64) \n",
    "\n",
    "        # multible classes\n",
    "        labels = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        for i in range(num_objs):\n",
    "            labels[i] = self.categories[labels_list[i]]\n",
    "        #print(labels)\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:,0])\n",
    "\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "        \n",
    "        return img, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dic(path):\n",
    "    if os.path.isfile(path):\n",
    "        return pickle.load( open( pathTrainDictionary, \"rb\" ) )\n",
    "    else:\n",
    "        print(\"no such file\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathDataset = \"../BaggagesData/dictionariesData\"\n",
    "pathTrainDictionary = pathDataset + \"/TestDicData.pkl\"\n",
    "imgbbox_test = load_dic(pathTrainDictionary)\n",
    "len(imgbbox_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(num_classes):\n",
    "  # load an object detection model pre-trained on COCO\n",
    "  model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "  # get the number of input features for the classifier\n",
    "  in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "  # replace the pre-trained head with a new on\n",
    "  model.roi_heads.box_predictor = FastRCNNPredictor(in_features,num_classes)\n",
    "   \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transform(train):\n",
    "    transforms = []\n",
    "   # converts the image, a PIL image, into a PyTorch Tensor\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "      # during training, randomly flip the training images\n",
    "      # and ground-truth for data augmentation\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load trained model\n",
    "cat = {'handgun': 1,'knife': 2, 'razorblade': 3, 'shuriken': 4}\n",
    "\n",
    "model_name = '../Trained_models/model_1465images_5Classes_5epochs_finished'\n",
    "loaded_model = get_model(num_classes = len(cat) +1 )\n",
    "\n",
    "if os.path.isfile(model_name):\n",
    "    loaded_model.load_state_dict(torch.load(model_name, map_location=torch.device('cpu') ))\n",
    "else:\n",
    "    print(\"Wrong path or filename\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pathDataset_test_imgs = \"../BaggagesData/Test\"\n",
    "\n",
    "# use our dataset and defined transformations\n",
    "dataset_test = WeaponDataset(dicPics = imgbbox_test, categories = cat, path = pathDataset_test_imgs, transforms = get_transform(train=False))   # Testing\n",
    "\n",
    "\n",
    "print(\"Test set: {} examples\".format(len(dataset_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idx = 20\n",
    "#for idx in range(1):\n",
    "\n",
    "cat_color = {1:\"red\", 2:\"yellow\", 3: \"blue\", 4:\"orange\"}\n",
    "\n",
    "img, _ = dataset_test[idx]\n",
    "\n",
    "label_boxes = np.array(dataset_test[idx][1][\"boxes\"])\n",
    "#put the model in evaluation mode\n",
    "loaded_model.eval()\n",
    "with torch.no_grad():\n",
    "    prediction = loaded_model([img])\n",
    "    \n",
    "image = Image.fromarray(img.mul(255).permute(1, 2,0).byte().numpy())\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "cat_rev = {cat[o]: o for o in cat}\n",
    "\n",
    "# draw groundtruth\n",
    "#for elem in range(len(label_boxes)):\n",
    "#    draw.rectangle([(label_boxes[elem][0], label_boxes[elem][1]),\n",
    "#    (label_boxes[elem][2], label_boxes[elem][3])], \n",
    "#    outline =\"green\", width =3)\n",
    "    \n",
    "for element in range(len(prediction[0][\"boxes\"])):\n",
    "\n",
    "    boxes = prediction[0][\"boxes\"][element].cpu().numpy()\n",
    "    score = np.round(prediction[0][\"scores\"][element].cpu().numpy(),\n",
    "                    decimals= 4)\n",
    "    if score > 0.8:\n",
    "\n",
    "        draw.rectangle([(boxes[0], boxes[1]), (boxes[2], boxes[3])], outline =cat_color[np.int(prediction[0][\"labels\"][element])], width =3)\n",
    "        draw.text((boxes[0], boxes[1]), text = str(score)+ \" \" + cat_rev[np.int(prediction[0][\"labels\"][element])] , fill=\"#000\")\n",
    "display(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = cat_rev\n",
    "\n",
    "TP, FP, FN, TN = 0, 0, 0, 0\n",
    "\n",
    "for idx in range(len(dataset_test)):\n",
    "    img, _ = dataset_test[idx]\n",
    "    with torch.no_grad():\n",
    "        prediction = loaded_model([img])\n",
    "    \n",
    "    gt_labels = dataset_test[idx][1][\"labels\"].numpy()\n",
    "    pred_labels = prediction[0][\"labels\"].numpy()[prediction[0][\"scores\"].numpy() > 0.7]\n",
    "    \n",
    "    if (gt_labels.any() == True and pred_labels.any() == True):\n",
    "        TP += 1\n",
    "    elif (gt_labels.any() == False and pred_labels.any() == True):\n",
    "        FP += 1\n",
    "    elif (gt_labels.any() == True and pred_labels.any() == False):\n",
    "        FN += 1\n",
    "    elif (gt_labels.any() == False and pred_labels.any() == False):\n",
    "        TN += 1\n",
    "\n",
    "    print(\"{}:\\tTP: {}\\t, FP: {}\\t, FN: {}\\t, TN, {}, \\t\\tAccuracy: {:.4f}\".format((idx+1),TP,FP,FN,TN, (1-((FP+FN)/(TP+TN)))))\n",
    "\n",
    "#for idx in range(len(dataset_test)):\n",
    "    #for label in pred_labels:\n",
    "    #    if label in gt_labels:\n",
    "    #        print(label, \" matches in \", gt_labels)\n",
    "    #        #danger = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
