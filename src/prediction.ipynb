{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../pytorchObjectDetection\")\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pycocotools\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import pandas as pd\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "import transforms as T\n",
    "import torchvision\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "os.chdir('../src')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeaponDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, dicPics,categories, path, transforms=None): \n",
    "        self.path = path\n",
    "        self.dicPics = dicPics\n",
    "        self.transforms = transforms\n",
    "        self.categories = categories\n",
    "        self.imgs = [o for o in dicPics]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = Image.open(self.path +\"/\"+ self.imgs[idx]).convert(\"RGB\")        \n",
    "        box_list = self.dicPics[self.imgs[idx]][0]\n",
    "        target = {}\n",
    "        if len(box_list) is not 0:\n",
    "        \n",
    "            boxes = torch.as_tensor(box_list, dtype=torch.float32)\n",
    "            num_objs = len(box_list)\n",
    "            labels_list =  self.dicPics[self.imgs[idx]][1]\n",
    "\n",
    "            # multible classes\n",
    "            labels = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "            for i in range(num_objs):\n",
    "                labels[i] = self.categories[labels_list[i]]\n",
    "            #print(labels)\n",
    "            image_id = torch.tensor([idx])\n",
    "            area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:,0])\n",
    "\n",
    "            # suppose all instances are not crowd\n",
    "            iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "            target[\"boxes\"] = boxes\n",
    "            target[\"labels\"] = labels\n",
    "            target[\"image_id\"] = image_id\n",
    "            target[\"area\"] = area\n",
    "            target[\"iscrowd\"] = iscrowd\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "        \n",
    "        return img, target\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    \n",
    "\n",
    "\n",
    "def load_dic(path):\n",
    "    if os.path.isfile(path):\n",
    "        return pickle.load( open( path, \"rb\" ) )\n",
    "    else:\n",
    "        print(\"no such file\")\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_model(num_classes):\n",
    "    # load an object detection model pre-trained on COCO\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    # get the number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new on\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features,num_classes)\n",
    "    return model\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "   # converts the image, a PIL image, into a PyTorch Tensor\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "      # during training, randomly flip the training images\n",
    "      # and ground-truth for data augmentation\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dictionary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathDataset = \"../BaggagesData/dictionariesData\"\n",
    "pathTrainDictionary = pathDataset + \"/TestDicData.pkl\"\n",
    "imgbbox_test = load_dic(pathTrainDictionary)\n",
    "imgbbox_test_nw = load_dic(\"../BaggagesData/dictionariesData/test_nowp.pkl\") # baggage with no weapons\n",
    "imgbbox_test.update(imgbbox_test_nw)\n",
    "len(imgbbox_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load trained model\n",
    "cat = {'handgun ': 1,'knife   ': 2, 'razorblade': 3, 'shuriken': 4}\n",
    "\n",
    "model_name = '../Trained_models/model_1465images_5Classes_5epochs_finished'\n",
    "loaded_model = get_model(num_classes = len(cat) +1 )\n",
    "\n",
    "if os.path.isfile(model_name):\n",
    "    loaded_model.load_state_dict(torch.load(model_name, map_location=torch.device('cpu') ))\n",
    "    loaded_model.eval()\n",
    "else:\n",
    "    print(\"Wrong path or filename\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pathDataset_test_imgs = \"../BaggagesData/Test\"\n",
    "# use our dataset and defined transformations\n",
    "dataset_test = WeaponDataset(dicPics = imgbbox_test, categories = cat, path = pathDataset_test_imgs, transforms = get_transform(train=False))   # Testing\n",
    "\n",
    "print(\"Test set: {} examples\".format(len(dataset_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idx = 72\n",
    "#for idx in range(1):\n",
    "\n",
    "cat_color = {1:\"red\", 2:\"yellow\", 3: \"blue\", 4:\"orange\"}\n",
    "\n",
    "img, _ = dataset_test[idx]\n",
    "\n",
    "#label_boxes = np.array(dataset_test[idx][1][\"boxes\"])\n",
    "#put the model in evaluation mode\n",
    "with torch.no_grad():\n",
    "    prediction = loaded_model([img])\n",
    "    \n",
    "image = Image.fromarray(img.mul(255).permute(1, 2,0).byte().numpy())\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "cat_rev = {cat[o]: o for o in cat}\n",
    "\n",
    "# draw groundtruth\n",
    "#for elem in range(len(label_boxes)):\n",
    "#    draw.rectangle([(label_boxes[elem][0], label_boxes[elem][1]),\n",
    "#    (label_boxes[elem][2], label_boxes[elem][3])], \n",
    "#    outline =\"green\", width =3)\n",
    "    \n",
    "for element in range(len(prediction[0][\"boxes\"])):\n",
    "\n",
    "    boxes = prediction[0][\"boxes\"][element].cpu().numpy()\n",
    "    score = np.round(prediction[0][\"scores\"][element].cpu().numpy(),\n",
    "                    decimals= 4)\n",
    "    if score > 0.8:\n",
    "\n",
    "        draw.rectangle([(boxes[0], boxes[1]), (boxes[2], boxes[3])], outline =cat_color[np.int(prediction[0][\"labels\"][element])], width =3)\n",
    "        draw.text((boxes[0], boxes[1]), text = str(score)+ \" \" + cat_rev[np.int(prediction[0][\"labels\"][element])] , fill=\"#000\")\n",
    "display(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving predictions for faster runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list_labels = []\n",
    "gt_list_labels = []\n",
    "# for each image, save prediction\n",
    "for idx in range(len(dataset_test)):\n",
    "    \n",
    "    gt_lab = np.array([])\n",
    "    img, targets = dataset_test[idx]\n",
    "    if len(targets) is not 0:\n",
    "        gt_lab = targets[\"labels\"].numpy()\n",
    "    gt_list_labels.append(gt_lab)\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        prediction = loaded_model([img])[0]\n",
    "    pred_list_labels.append(prediction[\"labels\"].numpy()[prediction[\"scores\"].numpy() > 0.7])\n",
    "    \n",
    "    if (idx+1) % 5 == 0:\n",
    "        print(idx+1, \"/\", len(dataset_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # General baggage statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {cat[o]: o for o in cat}\n",
    "\n",
    "TP, FP, FN, TN = 0, 0, 0, 0\n",
    "\n",
    "# check if prediction matches ground truth\n",
    "for idx in range(len(dataset_test)):\n",
    "    gt_labels = gt_list_labels[idx]\n",
    "    pred_labels = pred_list_labels[idx]\n",
    "    \n",
    "    if  (gt_labels.any()  == True  and pred_labels.any() == True):\n",
    "        TP += 1\n",
    "    elif (gt_labels.any() == False and pred_labels.any() == True):\n",
    "        FP += 1\n",
    "    elif (gt_labels.any() == True  and pred_labels.any() == False):\n",
    "        FN += 1\n",
    "    elif (gt_labels.any() == False and pred_labels.any() == False):\n",
    "        TN += 1\n",
    "    \n",
    "\n",
    "print(\"\\nTP: {}, FP: {}, FN: {}, TN: {}  |  Accuracy: {:.4f},  Precision: {:.3f},  Recall: {:.3f}\".format(\n",
    "                                                       TP,FP,FN,TN,(1-((FP+FN)/(TP+TN))), TP/(TP+FP), TP/(TP+FN) )) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {cat[o]: o for o in cat}\n",
    "tp, tn, fp, fn = np.zeros(len(labels)), np.zeros(len(labels)), np.zeros(len(labels)), np.zeros(len(labels))\n",
    "\n",
    "for idx in range(1,len(dataset_test)):\n",
    "    gt_labels = gt_list_labels[idx]\n",
    "    pred_labels = pred_list_labels[idx]\n",
    "    \n",
    "    count_gt, count_pred = np.zeros(len(labels)), np.zeros(len(labels))\n",
    "    \n",
    "    for label in gt_labels:\n",
    "        count_gt[label-1] += 1\n",
    "    for label in pred_labels:\n",
    "        count_pred[label-1] += 1\n",
    "    \n",
    "    for i in range(len(labels)):\n",
    "        difference = count_pred[i] - count_gt[i]\n",
    "        \n",
    "        if difference == 0:\n",
    "            tp[i] += count_pred[i]\n",
    "            if count_pred[i] == 0 and count_gt[i] == 0:\n",
    "                tn[i] += 1\n",
    "        elif difference > 0:\n",
    "            tp[i] += count_gt[i]\n",
    "            fp[i] += difference\n",
    "\n",
    "        else:\n",
    "            tp[i] += count_pred[i]\n",
    "            fn[i] -= difference\n",
    "\n",
    "# print statistics\n",
    "for i in range(len(labels)):\n",
    "    print()\n",
    "    print(\"{}\\tTP: {}, FP: {}, FN: {};\\t   |  Precision: {:.3f},  Recall: {:.3f}\".format(\n",
    "        labels[i+1], tp[i], fp[i], fn[i], tp[i]/(tp[i]+fp[i]), tp[i]/(tp[i]+fn[i]) ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
